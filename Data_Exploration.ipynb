{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import hashlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11754 entries, 0 to 11753\n",
      "Data columns (total 3 columns):\n",
      "id           11754 non-null object\n",
      "jsonFile     11754 non-null object\n",
      "imageFile    11754 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 275.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jsonFile</th>\n",
       "      <th>imageFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122788</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/label3D/cam...</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/camera/cam_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80971</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/label3D/cam...</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/camera/cam_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87534</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/label3D/cam...</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/camera/cam_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113606</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/label3D/cam...</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/camera/cam_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36780</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/label3D/cam...</td>\n",
       "      <td>/data/Audi_dataset/20181204_135952/camera/cam_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           jsonFile  \\\n",
       "0  122788  /data/Audi_dataset/20181204_135952/label3D/cam...   \n",
       "1   80971  /data/Audi_dataset/20181204_135952/label3D/cam...   \n",
       "2   87534  /data/Audi_dataset/20181204_135952/label3D/cam...   \n",
       "3  113606  /data/Audi_dataset/20181204_135952/label3D/cam...   \n",
       "4   36780  /data/Audi_dataset/20181204_135952/label3D/cam...   \n",
       "\n",
       "                                           imageFile  \n",
       "0  /data/Audi_dataset/20181204_135952/camera/cam_...  \n",
       "1  /data/Audi_dataset/20181204_135952/camera/cam_...  \n",
       "2  /data/Audi_dataset/20181204_135952/camera/cam_...  \n",
       "3  /data/Audi_dataset/20181204_135952/camera/cam_...  \n",
       "4  /data/Audi_dataset/20181204_135952/camera/cam_...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "dictFiles = defaultdict(list)\n",
    "# Get all the filepaths for json and respective image files\n",
    "for dirpath, dirname, filenames in os.walk('./data/Audi_dataset'):\n",
    "    for file in filenames:\n",
    "        if fnmatch.fnmatch(file, '*_label3D_*.json'):\n",
    "            key = file.split('_')[3].split('.')[0].lstrip('0')\n",
    "            filepath = dirpath + '/' + file\n",
    "            dictFiles[key].append(filepath.lstrip('.'))\n",
    "        if fnmatch.fnmatch(file, '*_camera_*.png'):\n",
    "            key = file.split('_')[3].split('.')[0].lstrip('0')\n",
    "            filepath = dirpath + '/' + file\n",
    "            dictFiles[key].append(filepath.lstrip('.'))\n",
    "# DataFrame with all the filepaths for json and respective image files\n",
    "dataset = pd.DataFrame([(k, v[0],v[1]) for k, v in dictFiles.items()], columns = ['id','jsonFile','imageFile'])\n",
    "\n",
    "dataset.info()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8227, 3), (1176, 3), (2351, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset, val_dataset = np.split(dataset.sample(frac=1), \n",
    "                                                    [int(.7*len(dataset)), int(.8*len(dataset))])\n",
    "train_dataset.shape, test_dataset.shape, val_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesFile = './data/classes.txt'\n",
    "\n",
    "def audi_convert(data):\n",
    "    class_map = {name: idx for idx, name in enumerate(\n",
    "        open(classesFile).read().splitlines())}\n",
    "    logging.info(\"Class mapping loaded: %s\", class_map)\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "    for key, row in tqdm.tqdm(data.iterrows()):\n",
    "        tf_example = build_example(row, class_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    logging.info(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_example(row, class_map):\n",
    "    d = pd.read_json(cur_dir + row['jsonFile'])\n",
    "    d = d.loc[['2d_bbox','class']].transpose()    \n",
    "    img_path = cur_dir + row['imgFile']\n",
    "    height, width = plt.imread(img_path).shape[:2]\n",
    "    img_raw = open(img_path, 'rb').read()\n",
    "    key = hashlib.sha256(img_raw).hexdigest()\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "   \n",
    "    for k, val in d.iterrows():\n",
    "        x1 = val['2d_bbox'][0] if val['2d_bbox'][0] > 0 else 0\n",
    "        y1 = val['2d_bbox'][1] if val['2d_bbox'][1] > 0 else 0\n",
    "        x2 = val['2d_bbox'][2] if val['2d_bbox'][2] > 0 else 0\n",
    "        y2 = val['2d_bbox'][3] if val['2d_bbox'][3] > 0 else 0\n",
    "        \n",
    "        xminval = (float(x1) / width) if (float(x1) / width) < 1 else 1\n",
    "        yminval = (float(y1) / height) if (float(y1) / height) < 1 else 1\n",
    "        xmaxval = (float(x2) / width) if (float(x2) / width) < 1 else 1\n",
    "        ymaxval = (float(y2) / height) if (float(y2) / height) < 1 else 1\n",
    "        \n",
    "        xmin.append(xminval)\n",
    "        ymin.append(yminval)\n",
    "        xmax.append(xmaxval)\n",
    "        ymax.append(ymaxval)\n",
    "        classes_text.append(val['class'].encode('utf8'))\n",
    "        classes.append(class_map[val['class']])\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            row['imgFile'].encode('utf8')])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            row['imgFile'].encode('utf8')])),\n",
    "        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf8')])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['png'.encode('utf8')])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "    }))\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8227it [31:53,  4.35it/s]\n"
     ]
    }
   ],
   "source": [
    "output_file = './data/audi_train.tfrecord'\n",
    "audi_convert(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2351it [04:29,  8.94it/s]\n"
     ]
    }
   ],
   "source": [
    "output_file = './data/audi_val.tfrecord'\n",
    "audi_convert(val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
