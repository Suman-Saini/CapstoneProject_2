{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-max suppression makes use of a concept called “intersection over union” or IoU.\n",
    "# It takes as input two boxes, and calculates the ratio of the intersection\n",
    "# and union of the two boxes.\n",
    "def non_max_suppression(inputs, model_size, max_output_size,\n",
    "                       max_output_size_per_class, iou_threshold,\n",
    "                       confidence_threshold):\n",
    "    bbox, confs, class_probs = tf.split(inputs, [4, 1, -1], axis = -1)\n",
    "    bbox= bbox/model_size[0]\n",
    "    \n",
    "    scores = confs * class_probs\n",
    "    # This method returns: A tensor containing the non-max suppressed boxes.\n",
    "    # A tensor containing the scores for the boxes.\n",
    "    # A tensor containing the class for boxes.\n",
    "    # A tensor indicating the number of valid detections per batch item.\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes = tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores = tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class = max_output_size_per_class,\n",
    "        max_total_size = max_output_size,\n",
    "        iou_threshold = iou_threshold,\n",
    "        score_threshold = confidence_threshold)\n",
    "    return boxes, scores, classes, valid_detections   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(inputs, modelsize):\n",
    "    inputs = tf.image.resize(inputs, modelsize)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        class_names = f.read().splitlines()\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_boxes(inputs, model_size, max_output_size, max_output_size_per_class,\n",
    "                iou_threshold, confidence_threshold):\n",
    "    center_x, center_y, width, height, confidence, classes = tf.split(inputs, [1, 1, 1, 1, 1, -1], axis = -1)\n",
    "    \n",
    "    top_left_x = center_x - width / 2.0\n",
    "    top_left_y = center_y - height / 2.0\n",
    "    bottom_right_x = center_x + width / 2.0\n",
    "    bottom_right_y = center_y + height / 2.0\n",
    "    \n",
    "    inputs = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes],\n",
    "                      axis= -1)\n",
    "    boxes_dicts = non_max_suppression(inputs,\n",
    "                                     model_size,\n",
    "                                     max_output_size,\n",
    "                                     max_output_size_per_class,\n",
    "                                     iou_threshold,\n",
    "                                     confidence_threshold)\n",
    "    return boxes_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outputs(img, boxes, objectness, classes, nums, class_names):\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    boxes = np.array(boxes)\n",
    "    \n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((boxes[i, 0:2] * [img.shape[1], img.shape[0]]).astype(np.int32))\n",
    "        x2y2 = tuple((boxes[i, 2:4] * [img.shape[1], img.shape[0]]).astype(np.int32))\n",
    "        \n",
    "        img = cv2.rectangle(img, (x1y1), (x2y2), (255,0,0), 2)\n",
    "        \n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(class_names[int(classes[i])], objectness[i]),\n",
    "                         (x1y1), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
