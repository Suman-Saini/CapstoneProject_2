{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Add, BatchNormalization, Conv2D, \n",
    "                                     Concatenate, Input, ZeroPadding2D, \n",
    "                                     LeakyReLU, UpSampling2D)\n",
    "from tensorflow.keras import backend as backend\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    with open(cfgfile, 'r') as file:\n",
    "        # to remove unnecessary characters like '\\n' and '#'\n",
    "        # and variable 'lines' will have all lines of file yolov3.cfg\n",
    "        lines = [line.rstrip('\\n') for line in file if line != '\\n' and line[0] != '#']    \n",
    "    holder = {}\n",
    "    blocks = []\n",
    "    # loop over each line and store each key value pairs in holder dict holder\n",
    "    # and then that dictionary is stored in blocks list\n",
    "    for line in lines:\n",
    "        if line[0] == '[':\n",
    "            line = 'type=' + line[1:-1].rstrip()\n",
    "            if len(holder) != 0:\n",
    "                blocks.append(holder)\n",
    "                holder = {}\n",
    "        key, value = line.split('=')\n",
    "        holder[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(holder)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3Net(cfgfile, model_size, num_classes):\n",
    "    \n",
    "    blocks = parse_cfg(cfgfile)\n",
    "    \n",
    "    outputs = {}\n",
    "    output_filters = []\n",
    "    filters = []\n",
    "    out_pred = []\n",
    "    scale = 0\n",
    "    \n",
    "    inputs = input_image = Input(shape = model_size)\n",
    "    inputs = inputs / 255.0\n",
    "    \n",
    "    # The YOLOv3 has 5 layers types in general, they are: \n",
    "    # 1. Convolutional layer\n",
    "    # 2. Upsample layer\n",
    "    # 3. Route layer\n",
    "    # 4. Shortcut layer\n",
    "    # 5. Yolo layer\n",
    "    for i, block in enumerate(blocks[1:]):\n",
    "        \n",
    "        # In YOLOv3, there are 2 convolutional layer types, i.e with and without batch normalization layer.\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            \n",
    "            activation = block['activation']\n",
    "            filters = int(block['filters'])\n",
    "            kernel_size = int(block['size'])\n",
    "            strides = int(block['stride'])\n",
    "            \n",
    "            # If strides is greater than 1 then downsampling is performed,\n",
    "            # hence need to adjust the padding\n",
    "            if strides > 1:\n",
    "                inputs = ZeroPadding2D(((1, 0), (1, 0)))(inputs)\n",
    "            \n",
    "            inputs = Conv2D(filters,\n",
    "                            kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding='valid' if strides > 1 else 'same',\n",
    "                            name='conv_' + str(i),\n",
    "                            use_bias=False if (\"batch_normalize\" in block) else True)(inputs)\n",
    "            \n",
    "            # The convolutional layer followed by a batch normalization layer uses a Leaky ReLU activation layer,\n",
    "            # otherwise, it uses the linear activation by default.\n",
    "            if \"batch_normalize\" in block:\n",
    "                inputs = BatchNormalization(name='bnorm_'+str(i))(inputs)\n",
    "            if activation == 'leaky':\n",
    "                inputs = LeakyReLU(alpha=0.1, name='leaky_'+str(i))(inputs)\n",
    "        \n",
    "        # In YOLOv3, Upsampler layer performs upsampling of the previous fetaure map\n",
    "        # by a factor of 'stride' using bilinear upsampling method.\n",
    "        elif (block['type'] == 'upsample'):\n",
    "            stride = int(block['stride'])\n",
    "            inputs = UpSampling2D(stride)(inputs)\n",
    "        \n",
    "        # Route layer\n",
    "        elif (block['type'] == 'route'):\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            # Check if attribute 'layers' has 1 value or 2\n",
    "            # If it has 1 value such as -4, then we need to go backward 4 layers and then output\n",
    "            # the feature map from that layer.\n",
    "            # If it has 2 values such as -1 and 61, then we need to concatenate the feature map \n",
    "            # from a previous layer (-1) and the feature map from layer 61. \n",
    "            if len(block['layers']) > 1:\n",
    "                end = int(block['layers'][1]) - i\n",
    "                filters = output_filters[i + start] + output_filters[end]\n",
    "                inputs = tf.concat([outputs[i + start], outputs[i + end]], axis = -1)\n",
    "            else:\n",
    "                filters = output_filters[i + start]\n",
    "                inputs = outputs[i + start]\n",
    "                \n",
    "        # In Shortcut layer, we perform skip connection. If attribute 'from' has value -3, then\n",
    "        # go backward 3 payers and take the feature map from that layer and add it with feature\n",
    "        # map from previous layer.\n",
    "        elif (block['type'] == 'shortcut'):\n",
    "            from_ = int(block['from'])\n",
    "            inputs = outputs[i - 1] + outputs[i + from_]\n",
    "            \n",
    "        # In Yolo layer, first we check the 'mask' and 'anchors' values.\n",
    "        elif (block['type'] == 'yolo'):\n",
    "            mask = block['mask'].split(',')\n",
    "            mask = [int(x) for x in mask]\n",
    "            #num_classes = int(block['classes'])\n",
    "            anchors = block['anchors'].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[j], anchors[j+1]) for j in range(0,len(anchors),2)]\n",
    "            anchors = [anchors[j] for j in mask]\n",
    "            # Reshape the YOLO output to the form of [None, B*grid_size*grid_size, 5+C]\n",
    "            # where B is the number of anchors and C is the number of classes\n",
    "            n_anchors = len(anchors)\n",
    "            out_shape = inputs.get_shape().as_list()\n",
    "            \n",
    "            inputs = tf.reshape(inputs, [-1, n_anchors * out_shape[1] * out_shape[2], \\\n",
    "                                        5 + num_classes])\n",
    "            \n",
    "            \n",
    "            box_centers = inputs[:, :, 0:2]\n",
    "            \n",
    "            box_shapes = inputs[:, :, 2:4]\n",
    "            confidence = inputs[:, :, 4:5]\n",
    "            classes = inputs[:, :, 5:num_classes + 5]\n",
    "            \n",
    "            # Refining Bounding Boxes\n",
    "            # Use the sigmoid function to convert box_centers, confidence and classes values \n",
    "            # into range of 0 - 1.\n",
    "            box_centers = tf.nn.sigmoid(box_centers)\n",
    "            confidence = tf.nn.sigmoid(confidence)\n",
    "            classes = tf.nn.sigmoid(classes)\n",
    "          \n",
    "            # Convert box_shapes\n",
    "            anchors = tf.tile(anchors, [out_shape[1] * out_shape[2], 1])\n",
    "            box_shapes = tf.exp(box_shapes) * tf.cast(anchors, dtype = tf.float32)\n",
    "            \n",
    "            x = tf.range(out_shape[1], dtype = tf.float32)\n",
    "            y = tf.range(out_shape[2], dtype = tf.float32)\n",
    "           \n",
    "            \n",
    "            # Using meshgrid to convert the relative positions of the center boxes\n",
    "            # into real positions\n",
    "            cx, cy = tf.meshgrid(x,y)\n",
    "            cx = tf.reshape(cx, (-1,1))\n",
    "            cy = tf.reshape(cy, (-1,1))\n",
    "            cxy = tf.concat([cx, cy], axis = -1)\n",
    "            cxy = tf.tile(cxy, [1, n_anchors])\n",
    "            cxy = tf.reshape(cxy, [1, -1, 2])\n",
    "            \n",
    "            strides = (input_image.shape[1] // out_shape[1], input_image.shape[2] // out_shape[2])\n",
    "            box_centers = (box_centers + cxy) * strides\n",
    "            \n",
    "            prediction = tf.concat([box_centers, box_shapes, confidence, classes], axis = -1)\n",
    "            \n",
    "            if scale:\n",
    "                out_pred = tf.concat([out_pred, prediction], axis = 1)\n",
    "            else:\n",
    "                out_pred = prediction\n",
    "                scale = 1\n",
    "            \n",
    "        # Since Route and Shortcut layers need output feature maps from previous layers\n",
    "        # so, we need to keep track of feature maps and output filters\n",
    "        outputs[i] = inputs\n",
    "        output_filters.append(filters)\n",
    "                \n",
    "    model = Model(input_image, out_pred)\n",
    "    model.summary()\n",
    "    #model.save('./data/yolov3.h5')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    '''Compose arbitrarily many functions, evaluated left to right.\n",
    "    '''\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv2D(*args, **kwargs):\n",
    "    '''Wrapper to set Darknet parameters for Convolution2D.'''\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    '''Darknet Convolution2D followed by BatchNormalization and LeakyReLU.'''\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "    x = DarknetConv2D_BN_Leaky(num_filters, (3,3), strides=(2,2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "                DarknetConv2D_BN_Leaky(num_filters//2, (1,1)),\n",
    "                DarknetConv2D_BN_Leaky(num_filters, (3,3)))(x)\n",
    "        x = Add()([x,y])\n",
    "    return x\n",
    "\n",
    "def darknet_body(x):\n",
    "    '''Darknent body having 52 Convolution2D layers'''\n",
    "    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
    "    y = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D(out_filters, (1,1)))(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V3 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(256, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors*(num_classes+5))\n",
    "\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors*(num_classes+5))\n",
    "\n",
    "    return Model(inputs, [y1,y2,y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    '''Convert final layer features to bounding box parameters.'''\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = backend.reshape(backend.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = backend.shape(feats)[1:3] # height, width\n",
    "    grid_y = backend.tile(backend.reshape(backend.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = backend.tile(backend.reshape(backend.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = backend.concatenate([grid_x, grid_y])\n",
    "    grid = backend.cast(grid, backend.dtype(feats))\n",
    "\n",
    "    feats = backend.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (backend.sigmoid(feats[..., :2]) + grid) / backend.cast(grid_shape[::-1], backend.dtype(feats))\n",
    "    box_wh = backend.exp(feats[..., 2:4]) * anchors_tensor / backend.cast(input_shape[::-1], backend.dtype(feats))\n",
    "    box_confidence = backend.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = backend.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(b1, b2):\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = backend.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = backend.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = backend.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = backend.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = backend.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = tf.cast(tf.shape(yolo_outputs[0])[1:3] * 32, backend.dtype(y_true[0]))\n",
    "    grid_shapes = [tf.cast(tf.shape(yolo_outputs[l])[1:3], backend.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = tf.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = tf.cast(m, backend.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
    "             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = backend.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = backend.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = backend.switch(object_mask, raw_true_wh, tf.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(backend.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = tf.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = backend.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, tf.cast(best_iou<ignore_thresh, backend.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = backend.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * backend.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * backend.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * backend.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * backend.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * backend.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = backend.sum(xy_loss) / mf\n",
    "        wh_loss = backend.sum(wh_loss) / mf\n",
    "        confidence_loss = backend.sum(confidence_loss) / mf\n",
    "        class_loss = backend.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, backend.sum(ignore_mask)], message='loss: ')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
