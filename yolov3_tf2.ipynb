{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Input, ZeroPadding2D, LeakyReLU, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    with open(cfgfile, 'r') as file:\n",
    "        # to remove unnecessary characters like '\\n' and '#'\n",
    "        # and lines will have all lines of file yolov3.cfg\n",
    "        lines = [line.rstrip('\\n') for line in file if line != '\\n' and line[0] != '#']    \n",
    "    holder = {}\n",
    "    blocks = []\n",
    "    # loop over each line and store each key value pairs in holder dict holder\n",
    "    # and then that dictionary is stored in blocks list\n",
    "    for line in lines:\n",
    "        if line[0] == '[':\n",
    "            line = 'type=' + line[1:-1].rstrip()\n",
    "            if len(holder) != 0:\n",
    "                blocks.append(holder)\n",
    "                holder = {}\n",
    "        key, value = line.split('=')\n",
    "        holder[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(holder)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'net',\n",
       "  'batch': '64',\n",
       "  'subdivisions': '16',\n",
       "  'width': '608',\n",
       "  'height': '608',\n",
       "  'channels': '3',\n",
       "  'momentum': '0.9',\n",
       "  'decay': '0.0005',\n",
       "  'angle': '0',\n",
       "  'saturation': '1.5',\n",
       "  'exposure': '1.5',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'burn_in': '1000',\n",
       "  'max_batches': '500200',\n",
       "  'policy': 'steps',\n",
       "  'steps': '400000,450000',\n",
       "  'scales': '.1,.1'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '42',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '6,7,8',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '9',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 61'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '42',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '3,4,5',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '9',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 36'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '42',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '0,1,2',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '9',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_cfg('cfg/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3Net(cfgfile, model_size, num_classes, inputs):\n",
    "    blocks = parse_cfg(cfgfile)\n",
    "    \n",
    "    outputs = {}\n",
    "    output_filters = []\n",
    "    filters = []\n",
    "    out_pred = []\n",
    "    scale = 0\n",
    "    \n",
    "    # The YOLOv3 has 5 layers types in general, they are: \n",
    "    # 1. Convolutional layer\n",
    "    # 2. Upsample layer\n",
    "    # 3. Route layer\n",
    "    # 4. Shortcut layer\n",
    "    # 5. Yolo layer\n",
    "    for i, block in enumerate(blocks[1:]):\n",
    "        \n",
    "        # In YOLOv3, there are 2 convolutional layer types, i.e with and without batch normalization layer.\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            \n",
    "            activation = block['activation']\n",
    "            filters = int(block['filters'])\n",
    "            kernel_size = int(block['size'])\n",
    "            strides = int(block['stride'])\n",
    "            \n",
    "            # If strides is greater than 1 then downsampling is performed,\n",
    "            # hence need to adjust the padding\n",
    "            if strides > 1:\n",
    "                inputs = ZeroPadding2D(((1, 0), (1, 0)))(inputs)\n",
    "\n",
    "            inputs = Conv2D(filters,\n",
    "                            kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding='valid' if strides > 1 else 'same',\n",
    "                            name='conv_' + str(i),\n",
    "                            use_bias=False if (\"batch_normalize\" in block) else True)(inputs)\n",
    "            \n",
    "            # The convolutional layer followed by a batch normalization layer uses a Leaky ReLU activation layer,\n",
    "            # otherwise, it uses the linear activation by default.\n",
    "            if \"batch_normalize\" in block:\n",
    "                inputs = BatchNormalization(name='bnorm_'+str(i))(inputs)\n",
    "            if activation == 'leaky':\n",
    "                inputs = LeakyReLU(alpha=0.1, name='leaky_'+str(i))(inputs)\n",
    "        \n",
    "        # In YOLOv3, Upsampler layer performs upsampling of the previous fetaure map\n",
    "        # using bilinear upsampling method.\n",
    "        elif (block['type'] == 'upsample'):\n",
    "            stride = int(block['stride'])\n",
    "            inputs = UpSampling2D(stride)(inputs)\n",
    "        \n",
    "        # Route layer\n",
    "        elif (block['type'] == 'route'):\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            # Check if attribute 'layers' has 1 value or 2\n",
    "            # If it has 1 value such as -4, then we need to go backward 4 layers and then output\n",
    "            # the feature map from that layer.\n",
    "            # If it has 2 values such as -1 and 61, then we need to concatenate the feature map \n",
    "            # from a previous layer (-1) and the feature map from layer 61. \n",
    "            if len(block['layers']) > 1:\n",
    "                end = int(block['layers'][1]) - i\n",
    "                filters = output_filters[i + start] + output_filters[end]\n",
    "                inputs = tf.concat([outputs[i + start], outputs[i + end]], axis = -1)\n",
    "            else:\n",
    "                filters = output_filters[i + start]\n",
    "                inputs = outputs[i + start]\n",
    "                \n",
    "        # In Shortcut layer, we perform skip connection. If attribute 'from' has value -3, then\n",
    "        # go backward 3 payers and take the feature map from that layer and add it with feature\n",
    "        # map from previous layer.\n",
    "        elif (block['type'] == 'shortcut'):\n",
    "            from_ = int(block['from'])\n",
    "            inputs = outputs[i - 1] + outputs[i + from_]\n",
    "            \n",
    "        # Yolo layer\n",
    "        elif (block['type'] == 'yolo'):\n",
    "            mask = block['mask'].split(',')\n",
    "            mask = [int(x) for x in mask]\n",
    "            anchors = block['anchors'].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[j], anchors[j+1]) for j in range(0,len(anchors),2)]\n",
    "            anchors = [anchors[j] for j in mask]\n",
    "           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 416, 416, 3])\n",
    "model_size = (416, 416,3)\n",
    "YOLOv3Net('cfg/yolov3.cfg',model_size,9,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
