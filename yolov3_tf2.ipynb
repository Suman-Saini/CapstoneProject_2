{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Input, ZeroPadding2D, LeakyReLU, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    with open(cfgfile, 'r') as file:\n",
    "        # to remove unnecessary characters like '\\n' and '#'\n",
    "        # and variable 'lines' will have all lines of file yolov3.cfg\n",
    "        lines = [line.rstrip('\\n') for line in file if line != '\\n' and line[0] != '#']    \n",
    "    holder = {}\n",
    "    blocks = []\n",
    "    # loop over each line and store each key value pairs in holder dict holder\n",
    "    # and then that dictionary is stored in blocks list\n",
    "    for line in lines:\n",
    "        if line[0] == '[':\n",
    "            line = 'type=' + line[1:-1].rstrip()\n",
    "            if len(holder) != 0:\n",
    "                blocks.append(holder)\n",
    "                holder = {}\n",
    "        key, value = line.split('=')\n",
    "        holder[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(holder)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3Net(cfgfile, model_size, num_classes):\n",
    "    \n",
    "    blocks = parse_cfg(cfgfile)\n",
    "    \n",
    "    outputs = {}\n",
    "    output_filters = []\n",
    "    filters = []\n",
    "    out_pred = []\n",
    "    scale = 0\n",
    "    \n",
    "    inputs = input_image = Input(shape = model_size)\n",
    "    inputs = inputs / 255.0\n",
    "    \n",
    "    # The YOLOv3 has 5 layers types in general, they are: \n",
    "    # 1. Convolutional layer\n",
    "    # 2. Upsample layer\n",
    "    # 3. Route layer\n",
    "    # 4. Shortcut layer\n",
    "    # 5. Yolo layer\n",
    "    for i, block in enumerate(blocks[1:]):\n",
    "        \n",
    "        # In YOLOv3, there are 2 convolutional layer types, i.e with and without batch normalization layer.\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            \n",
    "            activation = block['activation']\n",
    "            filters = int(block['filters'])\n",
    "            kernel_size = int(block['size'])\n",
    "            strides = int(block['stride'])\n",
    "            \n",
    "            # If strides is greater than 1 then downsampling is performed,\n",
    "            # hence need to adjust the padding\n",
    "            if strides > 1:\n",
    "                inputs = ZeroPadding2D(((1, 0), (1, 0)))(inputs)\n",
    "            \n",
    "            inputs = Conv2D(filters,\n",
    "                            kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding='valid' if strides > 1 else 'same',\n",
    "                            name='conv_' + str(i),\n",
    "                            use_bias=False if (\"batch_normalize\" in block) else True)(inputs)\n",
    "            \n",
    "            # The convolutional layer followed by a batch normalization layer uses a Leaky ReLU activation layer,\n",
    "            # otherwise, it uses the linear activation by default.\n",
    "            if \"batch_normalize\" in block:\n",
    "                inputs = BatchNormalization(name='bnorm_'+str(i))(inputs)\n",
    "            if activation == 'leaky':\n",
    "                inputs = LeakyReLU(alpha=0.1, name='leaky_'+str(i))(inputs)\n",
    "        \n",
    "        # In YOLOv3, Upsampler layer performs upsampling of the previous fetaure map\n",
    "        # by a factor of 'stride' using bilinear upsampling method.\n",
    "        elif (block['type'] == 'upsample'):\n",
    "            stride = int(block['stride'])\n",
    "            inputs = UpSampling2D(stride)(inputs)\n",
    "        \n",
    "        # Route layer\n",
    "        elif (block['type'] == 'route'):\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            # Check if attribute 'layers' has 1 value or 2\n",
    "            # If it has 1 value such as -4, then we need to go backward 4 layers and then output\n",
    "            # the feature map from that layer.\n",
    "            # If it has 2 values such as -1 and 61, then we need to concatenate the feature map \n",
    "            # from a previous layer (-1) and the feature map from layer 61. \n",
    "            if len(block['layers']) > 1:\n",
    "                end = int(block['layers'][1]) - i\n",
    "                filters = output_filters[i + start] + output_filters[end]\n",
    "                inputs = tf.concat([outputs[i + start], outputs[i + end]], axis = -1)\n",
    "            else:\n",
    "                filters = output_filters[i + start]\n",
    "                inputs = outputs[i + start]\n",
    "                \n",
    "        # In Shortcut layer, we perform skip connection. If attribute 'from' has value -3, then\n",
    "        # go backward 3 payers and take the feature map from that layer and add it with feature\n",
    "        # map from previous layer.\n",
    "        elif (block['type'] == 'shortcut'):\n",
    "            from_ = int(block['from'])\n",
    "            inputs = outputs[i - 1] + outputs[i + from_]\n",
    "            \n",
    "        # In Yolo layer, first we check the 'mask' and 'anchors' values.\n",
    "        elif (block['type'] == 'yolo'):\n",
    "            mask = block['mask'].split(',')\n",
    "            mask = [int(x) for x in mask]\n",
    "            #num_classes = int(block['classes'])\n",
    "            anchors = block['anchors'].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[j], anchors[j+1]) for j in range(0,len(anchors),2)]\n",
    "            anchors = [anchors[j] for j in mask]\n",
    "            # Reshape the YOLO output to the form of [None, B*grid_size*grid_size, 5+C]\n",
    "            # where B is the number of anchors and C is the number of classes\n",
    "            n_anchors = len(anchors)\n",
    "            out_shape = inputs.get_shape().as_list()\n",
    "            \n",
    "            inputs = tf.reshape(inputs, [-1, n_anchors * out_shape[1] * out_shape[2], \\\n",
    "                                        5 + num_classes])\n",
    "            \n",
    "            \n",
    "            box_centers = inputs[:, :, 0:2]\n",
    "            \n",
    "            box_shapes = inputs[:, :, 2:4]\n",
    "            confidence = inputs[:, :, 4:5]\n",
    "            classes = inputs[:, :, 5:num_classes + 5]\n",
    "            \n",
    "            # Refining Bounding Boxes\n",
    "            # Use the sigmoid function to convert box_centers, confidence and classes values \n",
    "            # into range of 0 - 1.\n",
    "            box_centers = tf.nn.sigmoid(box_centers)\n",
    "            confidence = tf.nn.sigmoid(confidence)\n",
    "            classes = tf.nn.sigmoid(classes)\n",
    "          \n",
    "            # Convert box_shapes\n",
    "            anchors = tf.tile(anchors, [out_shape[1] * out_shape[2], 1])\n",
    "            box_shapes = tf.exp(box_shapes) * tf.cast(anchors, dtype = tf.float32)\n",
    "            \n",
    "            x = tf.range(out_shape[1], dtype = tf.float32)\n",
    "            y = tf.range(out_shape[2], dtype = tf.float32)\n",
    "           \n",
    "            \n",
    "            # Using meshgrid to convert the relative positions of the center boxes\n",
    "            # into real positions\n",
    "            cx, cy = tf.meshgrid(x,y)\n",
    "            cx = tf.reshape(cx, (-1,1))\n",
    "            cy = tf.reshape(cy, (-1,1))\n",
    "            cxy = tf.concat([cx, cy], axis = -1)\n",
    "            cxy = tf.tile(cxy, [1, n_anchors])\n",
    "            cxy = tf.reshape(cxy, [1, -1, 2])\n",
    "            \n",
    "            strides = (input_image.shape[1] // out_shape[1], input_image.shape[2] // out_shape[2])\n",
    "            box_centers = (box_centers + cxy) * strides\n",
    "            \n",
    "            prediction = tf.concat([box_centers, box_shapes, confidence, classes], axis = -1)\n",
    "            \n",
    "            if scale:\n",
    "                out_pred = tf.concat([out_pred, prediction], axis = 1)\n",
    "            else:\n",
    "                out_pred = prediction\n",
    "                scale = 1\n",
    "            \n",
    "        # Since Route and Shortcut layers need output feature maps from previous layers\n",
    "        # so, we need to keep track of feature maps and output filters\n",
    "        outputs[i] = inputs\n",
    "        output_filters.append(filters)\n",
    "                \n",
    "    model = Model(input_image, out_pred)\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
